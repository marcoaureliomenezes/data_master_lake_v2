version: '2.1'
services:

######################################################
# DATABASE SERVICE
######################################################

  mysql:
    image: mysql
    command: --default-authentication-plugin=mysql_native_password
    container_name: mysql
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: root
      MYSQL_DATABASE: data_master

    healthcheck:
      test: ["CMD", 'mysqladmin', 'ping', '-h', 'mysql', '-u', 'root', '-p$$MYSQL_ROOT_PASSWORD' ]
      timeout: 45s
      interval: 10s
      retries: 10

  mongo:
    image: mongo:latest
    container_name: db_mongo
    environment:
      - PUID=1000
      - PGID=1000
    restart: unless-stopped
    ports:
      - "2717:27017"

  # DATABASE POSTGRES: FOR AIRFLOW (SPOORTS LOCAL EXECUTOR)    
  postgres:
    build: './docker/postgres'
    restart: always
    container_name: airflow-postgres-db
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"
    ports:
      - "32769:5432"
    volumes:
      - ./mnt/postgres:/var/lib/postgresql/data/pgdata
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow_db
      - PGDATA=/var/lib/postgresql/data/pgdata
    healthcheck:
      test: [ "CMD", "pg_isready", "-q", "-d", "airflow_db", "-U", "airflow" ]
      timeout: 45s
      interval: 10s
      retries: 10



######################################################
# HADOOP SERVICES
######################################################

  # NAMENODE HADOOP(Contains the metadata)
  namenode:
    build: ./docker/hadoop/hadoop-namenode
    restart: always
    container_name: hadoop-namenode
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"
    ports:
      - "32763:9870"
    volumes:
      - ./mnt/hadoop/namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=hadoop_cluster
    healthcheck:
      test: [ "CMD", "nc", "-z", "namenode", "9870" ]
      timeout: 45s
      interval: 10s
      retries: 10

  # DATANODE HADOOP (Contains the metadata)
  datanode1:
    build: ./docker/hadoop/hadoop-datanode
    restart: always
    container_name: hadoop-datanode1
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"
    depends_on:
      - namenode
    volumes:
      - ./mnt/hadoop/datanode:/hadoop/dfs/data
    environment:
      - SERVICE_PRECONDITION=namenode:9870
    healthcheck:
      test: [ "CMD", "nc", "-z", "datanode1", "9864" ]
      timeout: 45s
      interval: 10s
      retries: 10

  # DATANODE HADOOP (Contains the metadata)
  datanode2:
    build: ./docker/hadoop/hadoop-datanode
    restart: always
    container_name: hadoop-datanode2
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"
    depends_on:
      - namenode
    volumes:
      - ./mnt/hadoop/datanode:/hadoop/dfs/data
    environment:
      - SERVICE_PRECONDITION=namenode:9870
    healthcheck:
      test: [ "CMD", "nc", "-z", "datanode2", "9865" ]
      timeout: 45s
      interval: 10s
      retries: 10

  hive-metastore:
    build: ./docker/hive/hive-metastore
    restart: always
    container_name: hive-metastore
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"
    depends_on:
      - namenode
      - datanode1
      - postgres
    environment:
      - SERVICE_PRECONDITION=namenode:9870 datanode1:9864 postgres:5432
    ports:
      - "32761:9083"
    healthcheck:
      test: [ "CMD", "nc", "-z", "hive-metastore", "9083" ]
      timeout: 45s
      interval: 10s
      retries: 10

  # HIVE SERVER
  hive-server:
    build: ./docker/hive/hive-server
    restart: always
    container_name: hive-server
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"
    depends_on:
      - hive-metastore
    environment:
      - SERVICE_PRECONDITION=hive-metastore:9083
    ports:
      - "32760:10000"
      - "32759:10002"
    healthcheck:
      test: [ "CMD", "nc", "-z", "hive-server", "10002" ]
      timeout: 45s
      interval: 10s
      retries: 10

  hue:
    build: ./docker/hue
    restart: always
    container_name: hadoop-hue
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"
    depends_on:
      - hive-server
      - postgres
    ports:
      - "32762:8888"
    volumes:
      - ./mnt/hue/hue.ini:/usr/share/hue/desktop/conf/z-hue.ini
    environment:
      - SERVICE_PRECONDITION=hive-server:10000 postgres:5432
    healthcheck:
      test: [ "CMD", "nc", "-z", "hue", "8888" ]
      timeout: 45s
      interval: 10s
      retries: 10

######################################################
# SPARK SERVICES
######################################################
  spark-master:
    build: ./docker/spark/spark-master
    restart: always
    container_name: spark-master
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"
    ports:
      - "32766:8082"
      - "32765:7077"
    volumes:
      - ./mnt/spark/apps:/opt/spark-apps
      - ./mnt/spark/data:/opt/spark-data
    healthcheck:
      test: [ "CMD", "nc", "-z", "spark-master", "8082" ]
      timeout: 45s
      interval: 10s
      retries: 10

  # SPARK WORKER1 (This service can scale).
  spark-worker1:
    build: ./docker/spark/spark-worker
    container_name: spark-worker1
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"
    depends_on:
      - spark-master
    ports:
      - "32764:8081"
    volumes:
      - ./mnt/spark/apps:/opt/spark-apps
      - ./mnt/spark/data:/opt/spark-data
    healthcheck:
      test: [ "CMD", "nc", "-z", "spark-worker1", "8081" ]
      timeout: 45s
      interval: 10s
      retries: 10

######################################################
# AIRFLOW - ORCHESTRATOR
######################################################

  airflow:
    build: ./docker/airflow
    restart: always
    container_name: airflow
    volumes:
      - ./mnt/airflow/airflow.cfg:/opt/airflow/airflow.cfg
      - ./mnt/airflow/dags:/opt/airflow/dags
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - 8080:8080
    healthcheck:
      test: [ "CMD", "nc", "-z", "airflow", "8080" ]
      timeout: 45s
      interval: 10s
      retries: 10

######################################################
# KAFKA SERVICES
######################################################
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    healthcheck:
      test: [ "CMD", "nc", "-z", "zookeeper", "2181" ]
      timeout: 45s
      interval: 10s
      retries: 10

  kafka:
    image: confluentinc/cp-server:7.0.1
    container_name: kafka-broker1
    restart: always
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "9094:9094"
    volumes:
      - ./mnt/kafka:/kafka
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_LISTENERS: INTERNAL://:9092,OUTSIDE://:9094
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,OUTSIDE://host.docker.internal:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,OUTSIDE:PLAINTEXT
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka:9092  
    healthcheck:
      test: [ "CMD", "nc", "-z", "kafka", "9092" ]
      timeout: 45s
      interval: 10s
      retries: 10


  control-center:
    image: confluentinc/cp-enterprise-control-center:6.0.1
    container_name: kafka-control-center
    hostname: control-center
    depends_on:
      - kafka
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'kafka:9092'
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      PORT: 9021
    healthcheck:
      test: [ "CMD", "nc", "-z", "control-center", "9021" ]
      timeout: 45s
      interval: 10s
      retries: 10

      
  ###################################    NIFI SERVICES    #########################################
  nifi01:
    image: apache/nifi:latest
    container_name: nifi01
    ports:
      - 6980:8080

    volumes: 
      - ./mnt/nifi/nifi_registry/database:/opt/nifi-registry/nifi-registry-current/database 
      - ./mnt/nifi/nifi_registry/flow_storage:/opt/nifi-registry/nifi-registry-current/flow_storage
      - ./mnt/nifi/nifi_vols:/opt/nifi/nifi-current/ls-target
      
    environment:
      - NIFI_WEB_HTTP_PORT=8080
      - NIFI_CLUSTER_IS_NODE=true
      - NIFI_CLUSTER_NODE_PROTOCOL_PORT=8082
      - NIFI_ZK_CONNECT_STRING=zookeeper:2181
      - NIFI_ELECTION_MAX_WAIT=1 min
      - NIFI_SENSITIVE_PROPS_KEY=marcoaurelioreis

######################################################
# NETWORK
######################################################

networks:
  default:
    name: airflow-network
